{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imp import reload\n",
    "import math\n",
    "import h5py\n",
    "import shutil\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import KFold\n",
    "from progiter import ProgIter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mymodule import Trasnformer_model, VAE_model\n",
    "from rdkit.Chem import MolFromSmiles, Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from collections import defaultdict\n",
    "\n",
    "random_state=34\n",
    "IPythonConsole.ipython_useSVG=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Vocab\n"
     ]
    }
   ],
   "source": [
    "# all drugs\n",
    "with open('/tf/notebooks/code_for_pub/smiles_files/smiles_drugcombANDchembl26.pickle','rb') as f:\n",
    "    a = pickle.load(f)\n",
    "with open('/tf/notebooks/code_for_pub/smiles_files/smiles_drugcomb_BY_cid_duplicated.pickle','rb') as f:\n",
    "    b = pickle.load(f)\n",
    "smiles = a.append(b).drop_duplicates().reset_index(drop=True)\n",
    "v = Trasnformer_model.WordVocab(smiles, max_size=None, min_freq=1)\n",
    "#dataset = Trasnformer_model.Seq2seqDataset(smiles, v, seq_len=145)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'eos_index',\n",
       " 'extend',\n",
       " 'freqs',\n",
       " 'from_seq',\n",
       " 'itos',\n",
       " 'load_vocab',\n",
       " 'mask_index',\n",
       " 'pad_index',\n",
       " 'save_vocab',\n",
       " 'sos_index',\n",
       " 'stoi',\n",
       " 'to_seq',\n",
       " 'unk_index',\n",
       " 'vectors',\n",
       " 'vocab_rerank']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 64 bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Trasnformer_model.TrfmSeq2seq(\n",
    "    in_size=len(v), \n",
    "    hidden_size = 16,\n",
    "    out_size=len(v),\n",
    "    n_layers=6\n",
    ")\n",
    "m = torch.load('/tf/notebooks/code_for_pub/_logs_as_python_files/transformer_training_logs/T16_model_best.pth.tar')\n",
    "model.load_state_dict(m['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Trasnformer_model.Seq2seqDataset(b.values, v, seq_len=145)\n",
    "to_encode = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version='1.0' encoding='iso-8859-1'?>\n",
       "<svg version='1.1' baseProfile='full'\n",
       "              xmlns='http://www.w3.org/2000/svg'\n",
       "                      xmlns:rdkit='http://www.rdkit.org/xml'\n",
       "                      xmlns:xlink='http://www.w3.org/1999/xlink'\n",
       "                  xml:space='preserve'\n",
       "width='450px' height='150px' >\n",
       "<rect style='opacity:1.0;fill:#FFFFFF;stroke:none' width='450' height='150' x='0' y='0'> </rect>\n",
       "<path d='M 127.037,89.9941 150.124,84.5941' style='fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 150.124,84.5941 173.211,79.194' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 124.466,79.0021 147.553,73.602' style='fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 147.553,73.602 170.64,68.202' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 171.926,73.698 178.676,51.3893' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 178.676,51.3893 185.426,29.0806' style='fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 171.926,73.698 186.821,89.5791' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 186.821,89.5791 201.716,105.46' style='fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 204.58,15.8591 223.907,11.3386' style='fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 223.907,11.3386 243.233,6.81818' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 243.233,6.81818 281.846,47.9877' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 240.791,20.7162 267.82,49.5349' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 281.846,47.9877 305.876,42.3671' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 305.876,42.3671 329.907,36.7464' style='fill:none;fill-rule:evenodd;stroke:#33CCCC;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 281.846,47.9877 265.499,102.012' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 261.382,105.874 276.296,121.774' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 276.296,121.774 291.209,137.675' style='fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 269.616,98.151 284.529,114.052' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 284.529,114.052 299.443,129.953' style='fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 265.499,102.012 246.173,106.533' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path d='M 246.173,106.533 226.846,111.053' style='fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<text x='108.179' y='95.9605' style='font-size:18px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000' ><tspan>O</tspan></text>\n",
       "<text x='171.965' y='29.0806' style='font-size:18px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#0000FF' ><tspan>NH</tspan></text>\n",
       "<text x='329.907' y='44.5398' style='font-size:18px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#33CCCC' ><tspan>F</tspan></text>\n",
       "<text x='295.326' y='152.589' style='font-size:18px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000' ><tspan>O</tspan></text>\n",
       "<text x='194.231' y='124.275' style='font-size:18px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#0000FF' ><tspan>NH</tspan></text>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7f31c46b7440>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checking. This should be 5-FU\n",
    "\n",
    "molecule = MolFromSmiles(''.join(v.from_seq(dataset[0]))[5:28])\n",
    "molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4153/4153... rate=134.49 Hz, eta=0:00:00, total=0:00:30, wall=01:23 UTC\n"
     ]
    }
   ],
   "source": [
    "fp_transformer_64 = np.zeros((len(dataset), 64+1), dtype=np.float)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cid,(ind, sm) in ProgIter(zip(b.index,enumerate(to_encode)), total=len(dataset)):\n",
    "        fp_transformer_64[ind]= np.hstack((np.array(cid) , model.encode(torch.t(sm)).reshape(-1)))\n",
    "\n",
    "df_fp_transformer_64 = pd.DataFrame(data=fp_transformer_64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_name = '/tf/notebooks/code_for_pub/smiles_files/drugcomb_drugs_export_OCT2020.csv'\n",
    "drugs = pd.read_csv(drugs_name, names=['dname','id', 'smiles', 'cid'], header=0) # oct2020 version\n",
    "\n",
    "mapping = defaultdict(list) \n",
    "for i in drugs.itertuples(): # map cid to id\n",
    "    mapping[i.cid] = i.id\n",
    "    \n",
    "df_fp_transformer_64.iloc[:,0] = df_fp_transformer_64.iloc[:,0].astype(int)\n",
    "df_fp_transformer_64.rename(columns={0:'cid'}, inplace=True)\n",
    "df_fp_transformer_64['cid'] = df_fp_transformer_64['cid'].map(mapping)\n",
    "df_fp_transformer_64.rename(columns={'cid':'id'}, inplace=True)\n",
    "df_fp_transformer_64.set_index(keys='id', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.017833</td>\n",
       "      <td>-0.066369</td>\n",
       "      <td>-0.028680</td>\n",
       "      <td>0.216570</td>\n",
       "      <td>0.051967</td>\n",
       "      <td>-0.051174</td>\n",
       "      <td>-0.005353</td>\n",
       "      <td>0.112651</td>\n",
       "      <td>-0.001576</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.822641</td>\n",
       "      <td>-3.049594</td>\n",
       "      <td>-0.407887</td>\n",
       "      <td>0.480870</td>\n",
       "      <td>-0.442266</td>\n",
       "      <td>0.196142</td>\n",
       "      <td>0.955286</td>\n",
       "      <td>-0.261621</td>\n",
       "      <td>0.583369</td>\n",
       "      <td>1.301811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.020109</td>\n",
       "      <td>-0.057423</td>\n",
       "      <td>-0.016948</td>\n",
       "      <td>0.157078</td>\n",
       "      <td>0.055972</td>\n",
       "      <td>-0.049414</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.106124</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.083084</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.825921</td>\n",
       "      <td>-3.074596</td>\n",
       "      <td>-0.405278</td>\n",
       "      <td>0.472952</td>\n",
       "      <td>-0.444017</td>\n",
       "      <td>0.196169</td>\n",
       "      <td>0.975859</td>\n",
       "      <td>-0.217412</td>\n",
       "      <td>0.597471</td>\n",
       "      <td>1.256750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.027824</td>\n",
       "      <td>-0.032918</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>-0.007332</td>\n",
       "      <td>0.066567</td>\n",
       "      <td>-0.044038</td>\n",
       "      <td>0.020478</td>\n",
       "      <td>0.084508</td>\n",
       "      <td>0.022263</td>\n",
       "      <td>0.102263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.827926</td>\n",
       "      <td>-3.067765</td>\n",
       "      <td>-0.417167</td>\n",
       "      <td>0.500369</td>\n",
       "      <td>-0.448673</td>\n",
       "      <td>0.187110</td>\n",
       "      <td>0.981258</td>\n",
       "      <td>-0.177586</td>\n",
       "      <td>0.594257</td>\n",
       "      <td>1.238373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.027769</td>\n",
       "      <td>-0.032945</td>\n",
       "      <td>0.011906</td>\n",
       "      <td>-0.007347</td>\n",
       "      <td>0.066575</td>\n",
       "      <td>-0.044028</td>\n",
       "      <td>0.020586</td>\n",
       "      <td>0.084441</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>0.102299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.826173</td>\n",
       "      <td>-3.065923</td>\n",
       "      <td>-0.417958</td>\n",
       "      <td>0.500914</td>\n",
       "      <td>-0.448405</td>\n",
       "      <td>0.185515</td>\n",
       "      <td>0.979248</td>\n",
       "      <td>-0.181459</td>\n",
       "      <td>0.593378</td>\n",
       "      <td>1.243197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.023623</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.004586</td>\n",
       "      <td>0.088406</td>\n",
       "      <td>0.060553</td>\n",
       "      <td>-0.047217</td>\n",
       "      <td>0.007928</td>\n",
       "      <td>0.097785</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.827924</td>\n",
       "      <td>-3.077395</td>\n",
       "      <td>-0.406876</td>\n",
       "      <td>0.484428</td>\n",
       "      <td>-0.444813</td>\n",
       "      <td>0.196352</td>\n",
       "      <td>0.978595</td>\n",
       "      <td>-0.197761</td>\n",
       "      <td>0.594403</td>\n",
       "      <td>1.245485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7   \\\n",
       "id                                                                         \n",
       "1  -0.017833 -0.066369 -0.028680  0.216570  0.051967 -0.051174 -0.005353   \n",
       "2  -0.020109 -0.057423 -0.016948  0.157078  0.055972 -0.049414  0.000251   \n",
       "3  -0.027824 -0.032918  0.011989 -0.007332  0.066567 -0.044038  0.020478   \n",
       "4  -0.027769 -0.032945  0.011906 -0.007347  0.066575 -0.044028  0.020586   \n",
       "5  -0.023623 -0.047175 -0.004586  0.088406  0.060553 -0.047217  0.007928   \n",
       "\n",
       "          8         9         10  ...        55        56        57        58  \\\n",
       "id                                ...                                           \n",
       "1   0.112651 -0.001576  0.078064  ... -0.822641 -3.049594 -0.407887  0.480870   \n",
       "2   0.106124  0.004925  0.083084  ... -0.825921 -3.074596 -0.405278  0.472952   \n",
       "3   0.084508  0.022263  0.102263  ... -0.827926 -3.067765 -0.417167  0.500369   \n",
       "4   0.084441  0.022224  0.102299  ... -0.826173 -3.065923 -0.417958  0.500914   \n",
       "5   0.097785  0.012289  0.090474  ... -0.827924 -3.077395 -0.406876  0.484428   \n",
       "\n",
       "          59        60        61        62        63        64  \n",
       "id                                                              \n",
       "1  -0.442266  0.196142  0.955286 -0.261621  0.583369  1.301811  \n",
       "2  -0.444017  0.196169  0.975859 -0.217412  0.597471  1.256750  \n",
       "3  -0.448673  0.187110  0.981258 -0.177586  0.594257  1.238373  \n",
       "4  -0.448405  0.185515  0.979248 -0.181459  0.593378  1.243197  \n",
       "5  -0.444813  0.196352  0.978595 -0.197761  0.594403  1.245485  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fp_transformer_64.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/tf/notebooks/code_for_pub/fp_files/fps_transformer_64bit_new.pickle','wb') as f:\n",
    "    pickle.dump(df_fp_transformer_64,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1024 bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrfmSeq2seq(\n",
       "  (embed): Embedding(58, 256)\n",
       "  (pe): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (trfm): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=58, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Trasnformer_model.TrfmSeq2seq(\n",
    "    in_size=len(v), \n",
    "    hidden_size = 256,\n",
    "    out_size=len(v),\n",
    "    n_layers=6\n",
    ")\n",
    "m = torch.load('/tf/notebooks/code_for_pub/_logs_as_python_files/transformer_training_logs/T256_model_best.pth.tar')\n",
    "model.load_state_dict(m['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Trasnformer_model.Seq2seqDataset(b.values, v, seq_len=145)\n",
    "to_encode = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4153/4153... rate=75.70 Hz, eta=0:00:00, total=0:00:54, wall=20:54 UTC\n"
     ]
    }
   ],
   "source": [
    "fp_transformer_1024 = np.zeros((len(dataset), 1024+1), dtype=np.float)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cid, (ind, sm) in ProgIter(zip(b.index,enumerate(to_encode)), total=len(dataset)):\n",
    "        fp_transformer_1024[ind]= np.hstack((np.array(cid) , model.encode(torch.t(sm)).reshape(-1)))\n",
    "\n",
    "fp_transformer_1024 = pd.DataFrame(data=fp_transformer_1024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_name = '/tf/notebooks/code_for_pub/smiles_files/drugcomb_drugs_export_OCT2020.csv'\n",
    "drugs = pd.read_csv(drugs_name, names=['dname','id', 'smiles', 'cid'], header=0) # oct2020 version\n",
    "\n",
    "mapping = defaultdict(list) \n",
    "for i in drugs.itertuples(): # map cid to id\n",
    "    mapping[i.cid] = i.id\n",
    "    \n",
    "fp_transformer_1024.iloc[:,0] = fp_transformer_1024.iloc[:,0].astype(int)\n",
    "fp_transformer_1024.rename(columns={0:'cid'}, inplace=True)\n",
    "fp_transformer_1024['cid'] = fp_transformer_1024['cid'].map(mapping)\n",
    "fp_transformer_1024.rename(columns={'cid':'id'}, inplace=True)\n",
    "fp_transformer_1024.set_index(keys='id', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.163175</td>\n",
       "      <td>0.583282</td>\n",
       "      <td>0.408211</td>\n",
       "      <td>0.067850</td>\n",
       "      <td>-0.215724</td>\n",
       "      <td>-0.103014</td>\n",
       "      <td>-1.134651</td>\n",
       "      <td>-0.112591</td>\n",
       "      <td>-2.348408</td>\n",
       "      <td>-0.510069</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.431290</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.055007</td>\n",
       "      <td>0.849483</td>\n",
       "      <td>0.135861</td>\n",
       "      <td>1.088838</td>\n",
       "      <td>-0.133459</td>\n",
       "      <td>0.074664</td>\n",
       "      <td>0.730141</td>\n",
       "      <td>0.339768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.163178</td>\n",
       "      <td>0.583281</td>\n",
       "      <td>0.408218</td>\n",
       "      <td>0.067851</td>\n",
       "      <td>-0.215724</td>\n",
       "      <td>-0.103012</td>\n",
       "      <td>-1.134651</td>\n",
       "      <td>-0.112591</td>\n",
       "      <td>-2.348407</td>\n",
       "      <td>-0.510074</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.431298</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>0.849428</td>\n",
       "      <td>0.135838</td>\n",
       "      <td>1.088819</td>\n",
       "      <td>-0.133430</td>\n",
       "      <td>0.074673</td>\n",
       "      <td>0.730105</td>\n",
       "      <td>0.339737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163181</td>\n",
       "      <td>0.583273</td>\n",
       "      <td>0.408231</td>\n",
       "      <td>0.067855</td>\n",
       "      <td>-0.215724</td>\n",
       "      <td>-0.103016</td>\n",
       "      <td>-1.134644</td>\n",
       "      <td>-0.112585</td>\n",
       "      <td>-2.348398</td>\n",
       "      <td>-0.510084</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.431322</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.054881</td>\n",
       "      <td>0.849362</td>\n",
       "      <td>0.135798</td>\n",
       "      <td>1.088803</td>\n",
       "      <td>-0.133403</td>\n",
       "      <td>0.074649</td>\n",
       "      <td>0.730104</td>\n",
       "      <td>0.339685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163183</td>\n",
       "      <td>0.583273</td>\n",
       "      <td>0.408235</td>\n",
       "      <td>0.067855</td>\n",
       "      <td>-0.215726</td>\n",
       "      <td>-0.103012</td>\n",
       "      <td>-1.134644</td>\n",
       "      <td>-0.112585</td>\n",
       "      <td>-2.348397</td>\n",
       "      <td>-0.510086</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.431303</td>\n",
       "      <td>0.019823</td>\n",
       "      <td>0.054865</td>\n",
       "      <td>0.849344</td>\n",
       "      <td>0.135798</td>\n",
       "      <td>1.088794</td>\n",
       "      <td>-0.133415</td>\n",
       "      <td>0.074659</td>\n",
       "      <td>0.730094</td>\n",
       "      <td>0.339680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.163183</td>\n",
       "      <td>0.583280</td>\n",
       "      <td>0.408225</td>\n",
       "      <td>0.067854</td>\n",
       "      <td>-0.215721</td>\n",
       "      <td>-0.103017</td>\n",
       "      <td>-1.134645</td>\n",
       "      <td>-0.112586</td>\n",
       "      <td>-2.348397</td>\n",
       "      <td>-0.510080</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.431323</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.054910</td>\n",
       "      <td>0.849379</td>\n",
       "      <td>0.135814</td>\n",
       "      <td>1.088787</td>\n",
       "      <td>-0.133418</td>\n",
       "      <td>0.074691</td>\n",
       "      <td>0.730089</td>\n",
       "      <td>0.339706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1         2         3         4         5         6         7     \\\n",
       "id                                                                         \n",
       "1   0.163175  0.583282  0.408211  0.067850 -0.215724 -0.103014 -1.134651   \n",
       "2   0.163178  0.583281  0.408218  0.067851 -0.215724 -0.103012 -1.134651   \n",
       "3   0.163181  0.583273  0.408231  0.067855 -0.215724 -0.103016 -1.134644   \n",
       "4   0.163183  0.583273  0.408235  0.067855 -0.215726 -0.103012 -1.134644   \n",
       "5   0.163183  0.583280  0.408225  0.067854 -0.215721 -0.103017 -1.134645   \n",
       "\n",
       "        8         9         10    ...      1015      1016      1017      1018  \\\n",
       "id                                ...                                           \n",
       "1  -0.112591 -2.348408 -0.510069  ... -1.431290  0.019932  0.055007  0.849483   \n",
       "2  -0.112591 -2.348407 -0.510074  ... -1.431298  0.019901  0.054955  0.849428   \n",
       "3  -0.112585 -2.348398 -0.510084  ... -1.431322  0.019832  0.054881  0.849362   \n",
       "4  -0.112585 -2.348397 -0.510086  ... -1.431303  0.019823  0.054865  0.849344   \n",
       "5  -0.112586 -2.348397 -0.510080  ... -1.431323  0.019864  0.054910  0.849379   \n",
       "\n",
       "        1019      1020      1021      1022      1023      1024  \n",
       "id                                                              \n",
       "1   0.135861  1.088838 -0.133459  0.074664  0.730141  0.339768  \n",
       "2   0.135838  1.088819 -0.133430  0.074673  0.730105  0.339737  \n",
       "3   0.135798  1.088803 -0.133403  0.074649  0.730104  0.339685  \n",
       "4   0.135798  1.088794 -0.133415  0.074659  0.730094  0.339680  \n",
       "5   0.135814  1.088787 -0.133418  0.074691  0.730089  0.339706  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_transformer_1024.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/tf/notebooks/code_for_pub/fp_files/fps_transformer_1024bit_new.pickle','wb') as f:\n",
    "    pickle.dump(fp_transformer_1024,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
